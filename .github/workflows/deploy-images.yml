# ========================================================================
# WORKFLOW: Creation et publication des images Docker avec dÃ©ploiement AWS
# ========================================================================
# Ce workflow:
# 1. DÃ©tecte les secrets (Gitleaks)
# 2. Analyse le code (CodeQL & SAST)
# 3. Valide le code source (formatting, linting)
# 4. ExÃ©cute les tests automatisÃ©s
# 5. Construit et publie les images Docker sur GitHub Container Registry
# 6. DÃ©ploie automatiquement sur AWS via Terraform
# 7. Permet la destruction manuelle de l'infrastructure (workflow_dispatch)
# ========================================================================

name: CI/CD Pipeline with AWS Deployment

# DÃ©clencheurs
on:
  push:
    branches:
      - develop
  # Permet le dÃ©clenchement manuel pour les opÃ©rations Terraform
  workflow_dispatch:
    inputs:
      terraform_action:
        description: 'Action Terraform Ã  exÃ©cuter'
        required: true
        type: choice
        options:
          - apply
          - destroy
        default: apply

# Variables d'environnement globales pour le registre Docker
env:
  REGISTRY: ghcr.io # GitHub Container Registry
  REPOSITORY: ${{ github.repository }}

jobs:
  # ======== JOB 1: DÃ‰TECTION DE SECRETS ========
  secret-scanning:
    name: Secret Detection (Gitleaks)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # RÃ©cupÃ¨re tout l'historique pour l'analyse complÃ¨te

      # Scan des secrets avec Gitleaks
      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }} # Optionnel pour la version Pro

      # Upload des rÃ©sultats en cas de dÃ©tection
      - name: Upload Gitleaks results
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: gitleaks-report
          path: gitleaks-report.json
          retention-days: 30

  # ======== JOB 2: ANALYSE DE CODE CODEQL ========
  codeql-analysis:
    name: CodeQL Security Analysis
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: ['javascript']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Initialise CodeQL
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: ${{ matrix.language }}
          queries: +security-and-quality # Utilise les requÃªtes de sÃ©curitÃ©

      # Analyse automatique pour JavaScript
      - name: Autobuild
        uses: github/codeql-action/autobuild@v3

      # ExÃ©cute l'analyse CodeQL
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: '/language:${{ matrix.language }}'

  # ======== JOB 3: ANALYSE STATIQUE (SAST) ========
  sast-analysis:
    name: Static Application Security Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Installation des dÃ©pendances pour l'analyse
      - name: Install dependencies
        run: npm install

      # Audit de sÃ©curitÃ© npm
      - name: Run npm audit
        run: npm audit --audit-level=moderate
        continue-on-error: true

      # Analyse ESLint avec focus sÃ©curitÃ©
      - name: Run ESLint security check
        run: npm run lint
        continue-on-error: true

      # Snyk pour analyse de vulnÃ©rabilitÃ©s (optionnel, nÃ©cessite SNYK_TOKEN)
      - name: Run Snyk security scan
        if: env.SNYK_TOKEN != ''
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
        continue-on-error: true

  # ======== JOB 4: VALIDATION DU CODE ========
  validate:
    name: Format and Lint
    needs: [secret-scanning, codeql-analysis, sast-analysis]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20' # Utilisation de Node.js v20 LTS

      # Installation des dÃ©pendances racine (ESLint, Prettier, etc.)
      - name: Install dependencies
        run: npm install

      # VÃ©rification du formatage avec Prettier
      - name: Check formatting
        run: npm run format:check

      # VÃ©rification des rÃ¨gles de code avec ESLint
      - name: Verify linting
        run: npm run lint

  # ======== JOB 5: TESTS AUTOMATISÃ‰S ========
  test:
    name: Run API Tests
    needs: validate # Ne dÃ©marre que si la validation rÃ©ussit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Installation des dÃ©pendances racine
      - name: Install dependencies
        run: npm install

      # Installation des dÃ©pendances spÃ©cifiques Ã  l'API
      - name: Install API dependencies
        working-directory: ./api
        run: npm install

      # ExÃ©cution des tests unitaires et d'intÃ©gration
      - name: Run API tests
        working-directory: ./api
        run: npm test

      # Upload des rÃ©sultats de tests
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: api-test-results
          path: api/coverage/
          retention-days: 30

  # ======== JOB 6: BUILD ET PUSH DES IMAGES DOCKER ========
  build-and-push-images:
    needs: [validate, test] # Ne dÃ©marre que si validation et tests rÃ©ussissent
    runs-on: ubuntu-latest
    permissions:
      contents: read # AccÃ¨s en lecture au repo
      packages: write # Autorisation d'Ã©criture pour publier les images

    # StratÃ©gie matrix pour construire plusieurs images en parallÃ¨le
    strategy:
      matrix:
        service: [api, thread, sender] # Liste des services Ã  construire
        include:
          - service: api
            context: ./api # Contexte de build pour API
          - service: thread
            context: ./thread # Contexte de build pour Thread
          - service: sender
            context: ./sender # Contexte de build pour Sender

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Authentification au GitHub Container Registry
      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Extraction du hash court du commit pour les tags d'image
      - name: Extract commit short SHA
        id: sha
        run: echo "SHORT_SHA=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      # Configuration de Docker Buildx pour construction multi-plateforme
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Conversion du nom du repo en minuscules (requis par ghcr.io)
      - name: Convert repository name to lowercase
        id: repo_name
        run: echo "REPO_NAME=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT

      # Construction et publication de l'image Docker
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.context }} # Utilise le contexte spÃ©cifique au service
          push: true # Publie l'image sur le registre
          tags: |
            ${{ env.REGISTRY }}/${{ steps.repo_name.outputs.REPO_NAME }}/${{ matrix.service }}:latest
            ${{ env.REGISTRY }}/${{ steps.repo_name.outputs.REPO_NAME }}/${{ matrix.service }}:${{ steps.sha.outputs.SHORT_SHA }}
          cache-from: type=gha # Utilise le cache GitHub Actions pour accÃ©lÃ©rer les builds
          cache-to: type=gha,mode=max

      # Scan de sÃ©curitÃ© de l'image Docker avec Trivy
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ steps.repo_name.outputs.REPO_NAME }}/${{ matrix.service }}:${{ steps.sha.outputs.SHORT_SHA }}
          format: 'sarif'
          output: 'trivy-results-${{ matrix.service }}.sarif'
        continue-on-error: true

      # Upload des rÃ©sultats Trivy vers GitHub Security
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results-${{ matrix.service }}.sarif'
          category: 'trivy-${{ matrix.service }}'
        continue-on-error: true

  # ======== JOB 7: VALIDATION TERRAFORM ========
  terraform-validate:
    name: Validate Terraform Configuration
    needs: build-and-push-images
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./terraform

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Configure AWS credentials for backend: export secrets into GITHUB_ENV if provided
      - name: Configure AWS credentials (for backend)
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
            echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
            echo "AWS_REGION=eu-central-1" >> $GITHUB_ENV
            echo "Exported AWS credentials into GITHUB_ENV"
          else
            echo "AWS secrets not present - using local backend"
          fi

      - name: Check AWS credentials presence
        id: check-aws
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "has_aws=true" >> $GITHUB_OUTPUT
          else
            echo "has_aws=false" >> $GITHUB_OUTPUT
          fi

      - name: Export TF_STATE_BUCKET secret (if provided)
        env:
          TF_STATE_BUCKET_SECRET: ${{ secrets.TF_STATE_BUCKET }}
        run: |
          if [ -n "${TF_STATE_BUCKET_SECRET-}" ]; then
            echo "TF_STATE_BUCKET=${TF_STATE_BUCKET_SECRET}" >> $GITHUB_ENV
            echo "Exported TF_STATE_BUCKET into GITHUB_ENV"
          else
            echo "TF_STATE_BUCKET not set"
          fi

      # Initialize Terraform with remote S3 backend if AWS creds are present; otherwise fall back to local
      - name: Terraform Init (backend-aware)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${AWS_ACCESS_KEY_ID-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY-}" ]; then
            # derive a stable bucket and lock table name from repo (lowercase, replace / with -)
            REPO_SAFE=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]' | tr '/' '-')
            BUCKET_NAME="${REPO_SAFE}-tfstate"
            LOCK_TABLE_NAME="${REPO_SAFE}-tf-lock"

            echo "Using S3 bucket: $BUCKET_NAME (no DynamoDB lock)"

            # choose bucket: prefer TF_STATE_BUCKET secret, otherwise derived bucket
            if [ -n "${TF_STATE_BUCKET-}" ]; then
              BUCKET_NAME="$TF_STATE_BUCKET"
              echo "Using TF_STATE_BUCKET from secrets: $BUCKET_NAME"
            else
              echo "No TF_STATE_BUCKET secret set; using derived bucket name: $BUCKET_NAME"
            fi

            # verify bucket exists (do NOT create it here - may lack permissions)
            if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
              echo "Bucket $BUCKET_NAME exists"
            else
              echo "ERROR: S3 bucket $BUCKET_NAME does not exist or is not accessible. Create it manually or set secret TF_STATE_BUCKET with an existing bucket."
              exit 1
            fi

            # Init terraform with S3-only backend (no DynamoDB locking)
            terraform init -backend-config="bucket=$BUCKET_NAME" -backend-config="key=terraform.tfstate" -backend-config="region=eu-central-1"
          else
            echo "AWS credentials not provided â€” initializing terraform with local backend"
            terraform init -backend=false
          fi

      # Installation de Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      # Formatage Terraform
      - name: Terraform Format Check
        run: terraform fmt -check -recursive
        continue-on-error: true

      # Validation Terraform

      - name: Terraform Validate
        run: terraform validate

      # Analyse de sÃ©curitÃ© Terraform avec tfsec
      - name: Run tfsec security scanner
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
          soft_fail: true

  # ======== JOB 8: DÃ‰PLOIEMENT AUTOMATIQUE SUR AWS ========
  terraform-deploy:
    name: Deploy to AWS with Terraform
    needs: terraform-validate
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.terraform_action == 'apply') }}
    environment:
      name: production
      url: ${{ steps.terraform-output.outputs.url }}
    defaults:
      run:
        working-directory: ./terraform

    permissions:
      contents: read
      id-token: write # NÃ©cessaire pour OIDC

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Configuration des credentials AWS (export into GITHUB_ENV if provided)
      - name: Check AWS credentials presence
        id: check-aws
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "has_aws=true" >> $GITHUB_OUTPUT
          else
            echo "has_aws=false" >> $GITHUB_OUTPUT
          fi

      - name: Configure AWS Credentials
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        run: |
          set -euo pipefail
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_REGION=eu-central-1" >> $GITHUB_ENV
          echo "Exported AWS credentials into GITHUB_ENV"

      - name: Export TF_STATE_BUCKET secret (if provided)
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        env:
          TF_STATE_BUCKET_SECRET: ${{ secrets.TF_STATE_BUCKET }}
        run: |
          if [ -n "${TF_STATE_BUCKET_SECRET-}" ]; then
            echo "TF_STATE_BUCKET=${TF_STATE_BUCKET_SECRET}" >> $GITHUB_ENV
            echo "Exported TF_STATE_BUCKET into GITHUB_ENV"
          else
            echo "TF_STATE_BUCKET not set"
          fi

      # Installation de Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      # Initialisation Terraform (backend-aware)
      - name: Terraform Init (backend-aware)
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${AWS_ACCESS_KEY_ID-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY-}" ]; then
            REPO_SAFE=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]' | tr '/' '-')
            BUCKET_NAME="${REPO_SAFE}-tfstate"
            LOCK_TABLE_NAME="${REPO_SAFE}-tf-lock"

            # choose bucket: prefer TF_STATE_BUCKET secret, otherwise derived bucket
            if [ -n "${TF_STATE_BUCKET-}" ]; then
              BUCKET_NAME="$TF_STATE_BUCKET"
              echo "Using TF_STATE_BUCKET from secrets: $BUCKET_NAME"
            else
              echo "No TF_STATE_BUCKET secret set; using derived bucket name: $BUCKET_NAME"
            fi

            if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
              echo "Bucket $BUCKET_NAME exists"
            else
              echo "ERROR: S3 bucket $BUCKET_NAME does not exist or is not accessible. Create it manually or set secret TF_STATE_BUCKET with an existing bucket."
              exit 1
            fi

            terraform init -backend-config="bucket=$BUCKET_NAME" -backend-config="key=terraform.tfstate" -backend-config="region=eu-central-1"
          else
            echo "AWS creds not present; running terraform init with local backend"
            terraform init -backend=false
          fi

      # Plan Terraform (utilise les valeurs par dÃ©faut de variables.tf)
      - name: Terraform Plan
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        id: plan
        run: |
          terraform plan -out=tfplan -no-color
          echo "exitcode=$?" >> $GITHUB_OUTPUT

      # Upload du plan pour rÃ©fÃ©rence
      - name: Upload Terraform Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: terraform/tfplan
          retention-days: 30

      # Application du plan Terraform
      # Toutes les variables sont automatiquement rÃ©cupÃ©rÃ©es depuis variables.tf
      - name: Terraform Apply
        if: ${{ steps.check-aws.outputs.has_aws == 'true' && steps.plan.outputs.exitcode == '0' }}
        run: terraform apply -auto-approve tfplan

      # RÃ©cupÃ©ration des outputs Terraform
      - name: Get Terraform Outputs
        id: terraform-output
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        run: |
          echo "url=$(terraform output -raw instance_public_ip 2>/dev/null || echo 'N/A')" >> $GITHUB_OUTPUT
          terraform output -json > terraform-outputs.json || echo '{}' > terraform-outputs.json

      # Upload des outputs Terraform
      - name: Upload Terraform Outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: terraform/terraform-outputs.json
          retention-days: 30

      # Notification du dÃ©ploiement
      - name: Deployment Summary
        if: always()
        run: |
          echo "## ðŸš€ Deployment Successful!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Infrastructure Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Region:** eu-central-1 (dÃ©finie dans variables.tf)" >> $GITHUB_STEP_SUMMARY
          echo "- **Prefix:** theotime (dÃ©fini dans variables.tf)" >> $GITHUB_STEP_SUMMARY
          echo "- **Instance Type:** t2.micro (dÃ©fini dans variables.tf)" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“‹ Variables utilisÃ©es automatiquement" >> $GITHUB_STEP_SUMMARY
          echo "Toutes les variables sont rÃ©cupÃ©rÃ©es depuis \`terraform/variables.tf\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Outputs" >> $GITHUB_STEP_SUMMARY
          terraform output || echo "Pas d'outputs disponibles"

  # ======== JOB 9: DESTRUCTION MANUELLE DE L'INFRASTRUCTURE ========
  terraform-destroy:
    name: Destroy AWS Infrastructure (Manual Only)
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.terraform_action == 'destroy' }}
    defaults:
      run:
        working-directory: ./terraform

    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Configuration des credentials AWS (export into GITHUB_ENV if provided)
      - name: Check AWS credentials presence
        id: check-aws
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "has_aws=true" >> $GITHUB_OUTPUT
          else
            echo "has_aws=false" >> $GITHUB_OUTPUT
          fi

      - name: Configure AWS Credentials
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        run: |
          set -euo pipefail
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_REGION=eu-central-1" >> $GITHUB_ENV
          echo "Exported AWS credentials into GITHUB_ENV"

      - name: Export TF_STATE_BUCKET secret (if provided)
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        env:
          TF_STATE_BUCKET_SECRET: ${{ secrets.TF_STATE_BUCKET }}
        run: |
          if [ -n "${TF_STATE_BUCKET_SECRET-}" ]; then
            echo "TF_STATE_BUCKET=${TF_STATE_BUCKET_SECRET}" >> $GITHUB_ENV
            echo "Exported TF_STATE_BUCKET into GITHUB_ENV"
          else
            echo "TF_STATE_BUCKET not set"
          fi

      # Installation de Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      # Initialisation Terraform (backend-aware)
      - name: Terraform Init (backend-aware)
        if: ${{ steps.check-aws.outputs.has_aws == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${AWS_ACCESS_KEY_ID-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY-}" ]; then
            REPO_SAFE=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]' | tr '/' '-')
            BUCKET_NAME="${REPO_SAFE}-tfstate"
            LOCK_TABLE_NAME="${REPO_SAFE}-tf-lock"

            # choose bucket: prefer TF_STATE_BUCKET secret, otherwise derived bucket
            if [ -n "${TF_STATE_BUCKET-}" ]; then
              BUCKET_NAME="$TF_STATE_BUCKET"
              echo "Using TF_STATE_BUCKET from secrets: $BUCKET_NAME"
            else
              echo "No TF_STATE_BUCKET secret set; using derived bucket name: $BUCKET_NAME"
            fi

            if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
              echo "Bucket $BUCKET_NAME exists"
            else
              echo "ERROR: S3 bucket $BUCKET_NAME does not exist or is not accessible. Create it manually or set secret TF_STATE_BUCKET with an existing bucket."
              exit 1
            fi

            terraform init -backend-config="bucket=$BUCKET_NAME" -backend-config="key=terraform.tfstate" -backend-config="region=eu-central-1"
          else
            echo "AWS creds not present; running terraform init with local backend"
            terraform init -backend=false
          fi

      # Plan de destruction
      - name: Terraform Destroy Plan
        run: terraform plan -destroy -out=destroy-plan

      # Confirmation et destruction
      - name: Terraform Destroy
        run: terraform destroy -auto-approve

      # Notification de destruction
      - name: Destruction Summary
        run: |
          echo "## ðŸ’¥ Infrastructure Destroyed!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Region:** eu-central-1" >> $GITHUB_STEP_SUMMARY
          echo "- **Prefix:** theotime" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Time:** $(date)" >> $GITHUB_STEP_SUMMARY
